{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ba71b23-170d-43f8-8602-ffe91d914046",
      "metadata": {
        "id": "2ba71b23-170d-43f8-8602-ffe91d914046"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "%matplotlib inline\n",
        "from datetime import datetime\n",
        "\n",
        "import geopandas as gp\n",
        "from shapely import wkt\n",
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import geopy\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from tqdm._tqdm_notebook import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b505744-8285-46a4-8108-f114ac407d0e",
      "metadata": {
        "id": "4b505744-8285-46a4-8108-f114ac407d0e"
      },
      "outputs": [],
      "source": [
        "cols_order =  ['id', 'area', '.geo',\n",
        "               '2021-04-15','2021-04-16','2021-04-18','2021-04-19','2021-04-20','2021-04-22','2021-04-23','2021-04-25','2021-04-26','2021-04-27','2021-04-28','2021-04-29','2021-04-30','2021-05-01',\n",
        "               '2021-05-02','2021-05-03','2021-05-04','2021-05-07','2021-05-08','2021-05-09','2021-05-10','2021-05-15','2021-05-16','2021-05-17','2021-05-19','2021-05-20','2021-05-21','2021-05-24',\n",
        "               '2021-05-26','2021-05-27','2021-05-29','2021-06-02','2021-06-03','2021-06-04','2021-06-05','2021-06-06','2021-06-07','2021-06-09','2021-06-10','2021-06-12','2021-06-13','2021-06-16',\n",
        "               '2021-06-18','2021-06-19','2021-06-20','2021-06-22','2021-06-25','2021-06-27','2021-06-28','2021-07-04','2021-07-05','2021-07-07','2021-07-08','2021-07-09','2021-07-13','2021-07-15',\n",
        "               '2021-07-17','2021-07-20','2021-07-26','2021-07-27','2021-07-29','2021-07-31','2021-08-01','2021-08-07','2021-08-10','2021-08-11','2021-08-12','2021-08-13','2021-08-23','2021-08-27']\n",
        "              \n",
        "df = pd.read_csv(\"../../common_data/Innopolis/train_dataset_train.csv\")[cols_order + ['crop']]\n",
        "sub = pd.read_csv(\"../../common_data/Innopolis/test_dataset_test.csv\")[cols_order]\n",
        "renamer = lambda x: x.split('mean_')[-1] if 'nd_mean' in x else x\n",
        "df.rename(mapper = renamer, axis=1, inplace=True)\n",
        "sub.rename(mapper = renamer, axis=1, inplace=True)       \n",
        "df = df[cols_order + ['crop']]\n",
        "sub = sub[cols_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "539788f2-47ec-4a25-b69d-87add2a45822",
      "metadata": {
        "id": "539788f2-47ec-4a25-b69d-87add2a45822"
      },
      "outputs": [],
      "source": [
        "f = pd.read_csv('../../Ivan/Inno/geo_coords.csv')[['id', 'centroid']]\n",
        "\n",
        "f['x'] = gp.GeoSeries.from_wkt(f['centroid']).x\n",
        "f['y'] = gp.GeoSeries.from_wkt(f['centroid']).y\n",
        "\n",
        "f = f[['id', 'x', 'y']]\n",
        "f.head()\n",
        "\n",
        "\n",
        "df = df.merge(f, on = 'id', how = 'left')\n",
        "sub = sub.merge(f, on = 'id', how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c403deef-bca4-41cf-9599-945d07c09b52",
      "metadata": {
        "id": "c403deef-bca4-41cf-9599-945d07c09b52"
      },
      "outputs": [],
      "source": [
        "def make_geo_cell(df):\n",
        "\n",
        "    df['y_05'] = (df['y'] // 1.5).astype(int)\n",
        "    df['x_05'] = (df['x'] // 1.5).astype(int)\n",
        "\n",
        "    df['geo_cell'] = df['y_05'].astype(str) + '_' + df['x_05'].astype(str)\n",
        "    \n",
        "    df.drop(['y_05', 'x_05'], axis=1, inplace=True)\n",
        "    \n",
        "    \n",
        "make_geo_cell(df)\n",
        "make_geo_cell(sub)\n",
        "\n",
        "df['val'] = 1\n",
        "cols = ['crop','geo_cell', 'id', 'val']\n",
        "df_pivot = df[cols].pivot_table(index = 'geo_cell', aggfunc = 'mean', values = 'val', columns = 'crop').fillna(0)\n",
        "df_pivot.columns = [f'crop_{i}' for i in df_pivot.columns]\n",
        "df_pivot.reset_index(inplace=True)\n",
        "df.drop('val', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f174cc2e-0202-4a9e-9af6-7d45dc9fa279",
      "metadata": {
        "id": "f174cc2e-0202-4a9e-9af6-7d45dc9fa279"
      },
      "outputs": [],
      "source": [
        "df = df.merge(df_pivot, on = 'geo_cell', how = 'left')\n",
        "sub = sub.merge(df_pivot, on = 'geo_cell', how = 'left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99bf39c9-410c-45de-a935-0538dcaee4ac",
      "metadata": {
        "id": "99bf39c9-410c-45de-a935-0538dcaee4ac"
      },
      "outputs": [],
      "source": [
        "X_array = df['x'].values\n",
        "Y_array = df['y'].values\n",
        "\n",
        "def near_feild_fs(df):  \n",
        "    X_array = df['x'].values\n",
        "    Y_array = df['y'].values\n",
        "    f = lambda x : np.sum(abs(X_array - x) <= 0.05)\n",
        "    df['x_n_near_05'] = df['x'].apply(f)\n",
        "    f = lambda x : np.sum(abs(X_array - x) <= 0.01)\n",
        "    df['x_n_near_01'] = df['x'].apply(f)\n",
        "    df['x_n_near_01_on_05'] = df['x_n_near_01']/df['x_n_near_05'] \n",
        "    f = lambda x : np.sum(abs(Y_array - x) <= 0.01)\n",
        "    df['y_n_near_01'] = df['y'].apply(f)\n",
        "    f = lambda x : np.sum(abs(Y_array - x) <= 0.05)\n",
        "    df['y_n_near_05'] = df['y'].apply(f)\n",
        "    df['y_n_near_01_on_05'] = df['y_n_near_01']/df['y_n_near_05']    \n",
        "    f = lambda x : np.mean(abs(X_array - x) <= 0.05)\n",
        "    df['x_n_near_05_mean'] = df['x'].apply(f)\n",
        "    f = lambda x : np.mean(abs(X_array - x) <= 0.01)\n",
        "    df['x_n_near_01_mean'] = df['x'].apply(f)\n",
        "    f = lambda x : np.mean(abs(Y_array - x) <= 0.01)\n",
        "    df['y_n_near_01_mean'] = df['y'].apply(f)\n",
        "    f = lambda x : np.mean(abs(Y_array - x) <= 0.05)\n",
        "    df['y_n_near_05_mean'] = df['y'].apply(f)\n",
        "    \n",
        "    \n",
        "near_feild_fs(df)\n",
        "near_feild_fs(sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fcbc6a5-ec51-401b-9e8b-3a075eefed41",
      "metadata": {
        "id": "9fcbc6a5-ec51-401b-9e8b-3a075eefed41",
        "outputId": "a5b61290-cd14-421a-a691-4a06ff0d1033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat_features []\n",
            "num_features 86\n",
            "targets ['crop']\n"
          ]
        }
      ],
      "source": [
        "fs2drop = ['geo_cell']\n",
        "\n",
        "drop_features = ['id', '.geo'] + fs2drop\n",
        "targets = ['crop']\n",
        "cat_features = [] \n",
        "\n",
        "filtered_features = [i for i in df.columns if (i not in targets and i not in drop_features)]\n",
        "num_features = [i for i in filtered_features if i not in cat_features]\n",
        "\n",
        "\n",
        "print('cat_features', cat_features)\n",
        "print('num_features', len(num_features))\n",
        "print('targets', targets)\n",
        "\n",
        "for c in cat_features:\n",
        "    df[c] = df[c].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c488b1c4-8a70-4d73-821f-0c821b38daaf",
      "metadata": {
        "id": "c488b1c4-8a70-4d73-821f-0c821b38daaf"
      },
      "outputs": [],
      "source": [
        "date_cols = [col for col in df.columns if '2021-' in col]\n",
        "\n",
        "agg_features = ['month_argmax','month_mean','month_5','month_7','max_mean_diff','month_max_mean_diff','argmin',\n",
        "                'mean','month_8','var','std','month_var','month_std','month_max','max','month_4','argmax','month_argmin','month_6']\n",
        "\n",
        "dates_4 = [col for col in date_cols if \"-04-\" in col]\n",
        "dates_5 = [col for col in date_cols if \"-05-\" in col]\n",
        "dates_6 = [col for col in date_cols if \"-06-\" in col]\n",
        "dates_7 = [col for col in date_cols if \"-07-\" in col]\n",
        "dates_8 = [col for col in date_cols if \"-08-\" in col]\n",
        "\n",
        "\n",
        "def make_stat_agg(df):\n",
        "    date_cols = [col for col in df.columns if '2021-' in col]\n",
        "    agg_features = ['month_argmax','month_mean','month_5','month_7','max_mean_diff','month_max_mean_diff','argmin',\n",
        "                    'mean','month_8','var','std','month_var','month_std','month_max','max','month_4','argmax','month_argmin','month_6']\n",
        "    dates_4 = [col for col in date_cols if \"-04-\" in col]\n",
        "    dates_5 = [col for col in date_cols if \"-05-\" in col]\n",
        "    dates_6 = [col for col in date_cols if \"-06-\" in col]\n",
        "    dates_7 = [col for col in date_cols if \"-07-\" in col]\n",
        "    dates_8 = [col for col in date_cols if \"-08-\" in col]\n",
        "    df[\"mean\"] = df[date_cols].values.mean(axis=1)\n",
        "    df[\"min\"] = df[date_cols].values.min(axis=1)\n",
        "    df[\"max\"] = df[date_cols].values.max(axis=1)\n",
        "    df[\"var\"] = df[date_cols].values.var(axis=1)\n",
        "    df[\"std\"] = df[date_cols].values.std(axis=1)\n",
        "    df[\"argmax\"] = np.argmax(df[date_cols].values, axis=1)\n",
        "    df[\"argmin\"] = np.argmin(df[date_cols].values, axis=1)\n",
        "    df[\"max_mean_diff\"] = df[\"max\"] - df[\"mean\"]\n",
        "    month_sum = np.array([df[dates_4].values.sum(axis=1), df[dates_5].values.sum(axis=1),\n",
        "                          df[dates_6].values.sum(axis=1), df[dates_7].values.sum(axis=1),\n",
        "                          df[dates_8].values.sum(axis=1)]).T\n",
        "    df[\"month_mean\"] = month_sum.mean(axis=1)\n",
        "    df[\"month_min\"] = month_sum.min(axis=1)\n",
        "    df[\"month_max\"] = month_sum.max(axis=1)\n",
        "    df[\"month_var\"] = month_sum.var(axis=1)\n",
        "    df[\"month_std\"] = month_sum.std(axis=1)\n",
        "    df[\"month_argmax\"] = np.argmax(month_sum, axis=1)\n",
        "    df[\"month_argmin\"] = np.argmin(month_sum, axis=1)\n",
        "    df[\"month_max_mean_diff\"] = df[\"month_max\"] - df[\"month_mean\"]\n",
        "    month_sum = pd.DataFrame(month_sum, columns=[\"month_4\", \"month_5\", \"month_6\", \"month_7\", \"month_8\"])\n",
        "    df = pd.concat([df, month_sum], axis=1)\n",
        "    return df, agg_features\n",
        "\n",
        "filtered_features += agg_features\n",
        "filtered_features = list(np.unique(filtered_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527b492f-30aa-464e-ad81-2221a4246769",
      "metadata": {
        "id": "527b492f-30aa-464e-ad81-2221a4246769"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../../common_data/Innopolis/train_dataset_livington_v4.csv\")\n",
        "sub = pd.read_csv(\"../../common_data/Innopolis/test_dataset_livington_v4.csv\")\n",
        "\n",
        "near_feild_fs(df)\n",
        "near_feild_fs(sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac0be05a-ca4c-4e91-b8a8-d0808ddc1fba",
      "metadata": {
        "tags": [],
        "id": "ac0be05a-ca4c-4e91-b8a8-d0808ddc1fba"
      },
      "outputs": [],
      "source": [
        "adress_features = [\"municipality\", \"municipality_type\", \"county\", \"county_type\", \"state\", \"state_type\",\n",
        "                   \"ISO3166-2-lvl4\", \"region\"]\n",
        "\n",
        "\n",
        "def get_county_type(county):\n",
        "    if \"район\" in county:\n",
        "        return \"район\"\n",
        "    if \"округ\" in county:\n",
        "        return \"округ\"\n",
        "    return \"другое\"\n",
        "    \n",
        "def get_state_type(state):\n",
        "    if \"область\" in state:\n",
        "        return \"область\"\n",
        "    if \"край\" in state:\n",
        "        return \"край\"\n",
        "    return \"другое\"\n",
        "\n",
        "def get_municipality_type(municipality):\n",
        "    if \"поселение\" in municipality:\n",
        "        return \"поселение\"\n",
        "    if \"сельсовет\" in municipality:\n",
        "        return \"сельсовет\"\n",
        "    return \"другое\"\n",
        "\n",
        "def get_adress(df):\n",
        "    df['municipality'] = df[\"location\"].apply(lambda x: x['address'].get('municipality', 'nan'))\n",
        "    df['municipality_type'] = df[\"municipality\"].apply(lambda county: get_municipality_type(county))\n",
        "    df['county'] = df[\"location\"].apply(lambda x: x['address'].get('county', 'nan'))\n",
        "    df['county_type'] = df[\"county\"].apply(lambda county: get_county_type(county))\n",
        "    df['state'] = df[\"location\"].apply(lambda x: x['address'].get('state', 'nan'))\n",
        "    df['state_type'] = df[\"state\"].apply(lambda state: get_state_type(state))\n",
        "    df['ISO3166-2-lvl4'] = df[\"location\"].apply(lambda x: x['address'].get('ISO3166-2-lvl4', 'nan'))\n",
        "    df['region'] = df[\"location\"].apply(lambda x: x['address'].get('region', 'nan'))\n",
        "    df['country_code'] = df[\"location\"].apply(lambda x: x['address'].get('country_code', 'nan'))\n",
        "    \n",
        "df[adress_features].sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de0ee31-252b-4cfe-ab7e-11fa24a17197",
      "metadata": {
        "tags": [],
        "id": "4de0ee31-252b-4cfe-ab7e-11fa24a17197"
      },
      "outputs": [],
      "source": [
        "adress_agg_features = [\"state_mean\", \"region_mean\", \"mean_state_mean_diff\", \"mean_region_mean_diff\",\n",
        "                       \"municipality_mean\", \"mean_municipality_mean_diff\"]\n",
        "\n",
        "for adress_feature in [\"municipality\", \"state\", \"region\"]:\n",
        "    \n",
        "    val_dict = sub.groupby(adress_feature)[\"mean\"].mean().to_dict()\n",
        "    df[f\"{adress_feature}_mean\"] = df[adress_feature].apply(lambda x: val_dict.get(x, 0.))\n",
        "    df[f\"mean_{adress_feature}_mean_diff\"] = df[f\"{adress_feature}_mean\"] - df[\"mean\"]\n",
        "    sub[f\"{adress_feature}_mean\"] = sub[adress_feature].apply(lambda x: val_dict.get(x, 0.))\n",
        "    sub[f\"mean_{adress_feature}_mean_diff\"] = sub[f\"{adress_feature}_mean\"] - sub[\"mean\"]\n",
        "\n",
        "df[adress_agg_features].head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b211b5-44a1-4439-b7a0-0595d741d5c3",
      "metadata": {
        "id": "e0b211b5-44a1-4439-b7a0-0595d741d5c3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../../common_data/Innopolis/train_dataset_livington_v4.csv\")\n",
        "sub = pd.read_csv(\"../../common_data/Innopolis/test_dataset_livington_v4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c45f47-9175-407f-b5d7-9c9eafa2e70e",
      "metadata": {
        "tags": [],
        "id": "91c45f47-9175-407f-b5d7-9c9eafa2e70e"
      },
      "outputs": [],
      "source": [
        "weather_cols = [\"tavg\", \"tmin\", \"tmax\", \"prcp\", \"snow\", \"wdir\", \"wspd\", \"wpgt\", \"pres\", \"tsun\"]\n",
        "\n",
        "def get_weather_info(df):\n",
        "    for date_col in tqdm.tqdm(date_cols):\n",
        "        weather_dict = {wc: [] for wc in weather_cols}\n",
        "        for i, row in df.iterrows():\n",
        "            date = date_col.split('-')\n",
        "            y,m,d = int(date[0]), int(date[1]), int(date[2])\n",
        "            start = datetime(y, m, d)\n",
        "            end = datetime(y, m, d)\n",
        "            \n",
        "            location = Point(row.x, row.y)\n",
        "            \n",
        "            stations = Stations()\n",
        "            stations = stations.nearby(row.x, row.y)\n",
        "            station = stations.fetch(10)\n",
        "\n",
        "            data = Daily(station, start, end)\n",
        "            data = data.fetch()\n",
        "            data.fillna(0., inplace=True)\n",
        "            \n",
        "            for wc in weather_cols:\n",
        "                try:\n",
        "                    weather_dict[wc].append(np.median(data[wc].values))\n",
        "                except Exception as e:\n",
        "                    print(e, data)\n",
        "                    weather_dict[wc].append(0.)\n",
        "                \n",
        "        for wc in weather_cols:\n",
        "            df[f\"{date_col}_{wc}\"] = weather_dict[wc]\n",
        "\n",
        "            \n",
        "weather_date_cols = []\n",
        "for date_col in date_cols:\n",
        "    for wc in weather_cols:\n",
        "        weather_date_cols.append(f\"{date_col}_{wc}\")\n",
        "\n",
        "\n",
        "df[weather_date_cols].sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df39b9eb-007c-46ca-a60e-7b6ef080ca9b",
      "metadata": {
        "id": "df39b9eb-007c-46ca-a60e-7b6ef080ca9b"
      },
      "outputs": [],
      "source": [
        "cat_features += adress_features\n",
        "cat_features = list(np.unique(cat_features))\n",
        "\n",
        "filtered_features += adress_features + adress_agg_features\n",
        "filtered_features = list(np.unique(filtered_features))\n",
        "\n",
        "filtered_features += weather_date_cols\n",
        "filtered_features = list(np.unique(filtered_features))\n",
        "\n",
        "cat_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c34600bf-bde6-4124-8fff-748ae0349e19",
      "metadata": {
        "tags": [],
        "id": "c34600bf-bde6-4124-8fff-748ae0349e19"
      },
      "outputs": [],
      "source": [
        "random_state = 42\n",
        "n_splits = 3\n",
        "clfs = []\n",
        "\n",
        "targets = ['crop']\n",
        "X = df[filtered_features].drop(targets, axis=1, errors='ignore')\n",
        "y = df[targets]\n",
        "\n",
        "kFold_random_state = [42]\n",
        "\n",
        "N = len(kFold_random_state)*n_splits\n",
        "\n",
        "for num, random_state in enumerate(kFold_random_state):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "            \n",
        "        clf = XGBClassifier(objective ='multi:softprob',\n",
        "                          colsample_bytree = 0.3,\n",
        "                          subsample = 0.8,\n",
        "                            \n",
        "                          eta = 0.001,\n",
        "                          learning_rate = 0.015,\n",
        "                          max_depth = 4,\n",
        "                          alpha = 10,\n",
        "                          n_jobs = -1, \n",
        "                          min_child_weight = 6,\n",
        "                          reg_alpha=0.1,\n",
        "                          reg_lambda = 0.1/2,\n",
        "                          nthread=4,\n",
        "                          gamma = 0.031,\n",
        "                          n_estimators = 5_000,\n",
        "                          early_stopping_rounds=300,\n",
        "                          eval_metric = 'mlogloss',\n",
        "                           )\n",
        "\n",
        "        clf.fit(X = X_train,\n",
        "                y = y_train,\n",
        "                verbose = 400,\n",
        "                eval_set=[(X_test, y_test)],\n",
        "               )\n",
        "\n",
        "        \n",
        "        clfs.append(clf)\n",
        "        \n",
        "\n",
        "y_pred = np.zeros((sub.shape[0], 7))\n",
        "scores = {'multi_logloss':[], 'Precision' : [], 'Recall' : []}\n",
        "for n, clf in enumerate(clfs):\n",
        "    y_pred += clf.predict_proba(sub[filtered_features])\n",
        "    scores['multi_logloss'].append(clf.best_score)\n",
        "y_pred /= N\n",
        "print('mean multi_logloss', np.mean(scores['multi_logloss'], dtype = 'float32'), np.std(scores['multi_logloss'], dtype = 'float16'), f'По {len(clfs)} моделям')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd92a713-c155-4b3f-a3a0-f84b83979e78",
      "metadata": {
        "id": "cd92a713-c155-4b3f-a3a0-f84b83979e78"
      },
      "outputs": [],
      "source": [
        "sample_solution = pd.read_csv('../../common_data/Innopolis/sample_solution.csv')\n",
        "sample_solution['crop'] = np.argmax(y_pred, axis=1)\n",
        "sample_solution.to_csv('./subs/xgb_more_geo_fs_solution.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}